{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sad = 128\n",
    "obd = 32\n",
    "fd = 64\n",
    "scaling_factor = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(2, 6, 5, stride=1, padding = 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, stride=1, padding = 2)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 5, stride=1, padding = 2)\n",
    "        # an affine operation: y = Wx + b\n",
    "        image_size = fd/8\n",
    "        self.fc1 = nn.Linear(32 * image_size * image_size, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('details.jpg',0)\n",
    "\n",
    "def crop(img, lu, rb):\n",
    "    return img[lu[0]:rb[0], lu[1]:rb[1]]\n",
    "    \n",
    "def resize(img, h, w):\n",
    "    return cv2.resize(img, (w, h)) \n",
    "\n",
    "def random_crop(sample, m=40):\n",
    "    h = sample.shape[1]\n",
    "    w = sample.shape[0]\n",
    "    mw = m\n",
    "    mh = m\n",
    "    \n",
    "    l = random.randint(0, w-mw)\n",
    "    r = random.randint(l+mw, w)\n",
    "    \n",
    "    u = random.randint(0, h-mh)\n",
    "    b = random.randint(u+mh, h)\n",
    "    \n",
    "    return crop(sample, (l, u), (r, b)), ((l, u), (r, b))\n",
    "    \n",
    "def display_boxes(img, boxL, boxT):\n",
    "#     print(boxL)\n",
    "#     print(boxT)\n",
    "    \n",
    "    t = cv2.rectangle(img,boxL[0],boxL[1],(255,0,0), 1)\n",
    "    t = cv2.rectangle(t,boxT[0],boxT[1],(0,255,0), 2)\n",
    "    cv2.imshow('image',resize(t, 640, 640))\n",
    "\n",
    "def display(img, L, T):\n",
    "    h = img.shape[0]\n",
    "    w = img.shape[1]\n",
    "    \n",
    "   \n",
    "    \n",
    "    boxL = center_to_box(*L)\n",
    "    boxT = center_to_box(*T)\n",
    "    display_boxes(img, boxL, boxT)\n",
    "    \n",
    "def box_to_center(lu, rb):\n",
    "    w = rb[0] - lu[0]\n",
    "    h = rb[1] - lu[1]\n",
    "    cx = (rb[0] + lu[0]) / 2\n",
    "    cy = (rb[1] + lu[1]) / 2\n",
    "    return cx, cy, w, h\n",
    "\n",
    "    \n",
    "def center_to_box(cx, cy, w, h, dtype=int):\n",
    "    lu = dtype((cx - w/2)), dtype((cy - h/2))\n",
    "    rb = dtype((cx + w/2)), dtype((cy + h/2))\n",
    "    return lu, rb\n",
    "\n",
    "    \n",
    "# img = crop(img, (20, 20), (40, 100))\n",
    "# img = resize(img, 20, 40)\n",
    "print(img.shape)\n",
    "# img, _ = random_crop(img)\n",
    "print(img.shape)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caseNo = 10000\n",
    "sample = img\n",
    "\n",
    "\n",
    "losses = []\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
    "\n",
    "# loss = nn.MSELoss()\n",
    "loss = nn.L1Loss()\n",
    "\n",
    "\n",
    "for i in tqdm(range(caseNo)):\n",
    "    search_area, _ = random_crop(sample, sad)\n",
    "    search_area = resize(search_area, sad, sad)\n",
    "    obj, box = random_crop(search_area, obd)\n",
    "\n",
    "    \n",
    "#     labels = box[0][0] / sad, box[0][1] / sad, box[1][0] / sad, box[1][1] / sad\n",
    "#     cx, cy, w, h = box_to_center(*box)\n",
    "    labels = list(map(lambda x: x/ 1, box_to_center(*box)))\n",
    "#     plt.imshow(obj)\n",
    "#     plt.imshow(cv2.rectangle(search_area,box[0],box[1],(255,0,0), 1))\n",
    "    \n",
    "    X = np.dstack([resize(search_area, fd, fd), resize(obj, fd, fd)]).transpose((2, 0, 1))\n",
    "#     X = np.dstack([resize(search_area, fd, fd), resize(obj, fd, fd)])\n",
    "#     print(X.shape)\n",
    "    \n",
    "    X = torch.tensor(([X/255])).float()\n",
    "    X = torch.autograd.Variable(X, requires_grad=True)\n",
    "    Y = net(X) * scaling_factor\n",
    "#     torch.autograd.Variable(torch.randn((3,5)), requires_grad=True)\n",
    "#     T = torch.autograd.Variable(torch.tensor(labels), requires_grad=False)\n",
    "#     T = torch.autograd.Variable(torch.tensor(labels, requires_grad=False), requires_grad=False)\n",
    "    T = torch.tensor([labels], requires_grad=False)\n",
    "    \n",
    "    l = loss(Y, T)\n",
    "\n",
    "    losses.append(l)\n",
    "    if i % 50 == 0:\n",
    "#         torch.save(net.state_dict(), \"net\")\n",
    "\n",
    "#         print(i, Y.data.numpy()[0], T.data.numpy()[0])\n",
    "        display(search_area, Y.data.numpy()[0], T.data.numpy()[0])\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "        if i % 1000 == 0:\n",
    "            t = list(map(lambda x:float(x.data.numpy()), losses))[-3000:]\n",
    "            pd.Series(t).plot()\n",
    "            plt.show()\n",
    "#         time.sleep(0.5)\n",
    "    \n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "#     print(X.shape)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "# pd.Series(losses).plot()\n",
    "\n",
    "t = map(lambda x:float(x.data.numpy()), losses)\n",
    "pd.Series(t).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = map(lambda x:float(x.data.numpy()), losses)\n",
    "pd.Series(t).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "999 [ 0.02457903  0.05061942 -0.08223155  0.10660891] [0.203125 0.46875  0.9375   0.984375]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
